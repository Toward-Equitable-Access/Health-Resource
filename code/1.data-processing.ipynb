{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa851e38",
   "metadata": {},
   "source": [
    "# 1. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a5b82d",
   "metadata": {},
   "source": [
    "## 1.1 Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c48ed8e",
   "metadata": {},
   "source": [
    "- Area: 49 U.S. states and D.C.\n",
    "- Data: Google Maps reviews for stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56df9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87882ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../google-map-data/store-review'\n",
    "\n",
    "file_list = [f'filtered_review-{state}.csv' for state in [\n",
    "    'Nebraska', 'Pennsylvania', 'Arkansas', 'Tennessee', 'Minnesota', 'Nevada',\n",
    "    'Alaska', 'Oregon', 'Wisconsin', 'Iowa', 'Kansas', 'Mississippi',\n",
    "    'South_Dakota', 'Vermont', 'Texas', 'Maryland', 'Utah', 'New_Hampshire',\n",
    "    'Arizona', 'Michigan', 'Alabama', 'South_Carolina', 'District_of_Columbia',\n",
    "    'New_Jersey', 'West_Virginia', 'Kentucky', 'Ohio', 'Delaware', 'Florida',\n",
    "    'Idaho', 'Louisiana', 'North_Dakota', 'Washington', 'Georgia', 'Illinois',\n",
    "    'Wyoming', 'Missouri', 'California', 'New_Mexico', 'New_York', 'Connecticut',\n",
    "    'Oklahoma', 'Colorado', 'North_Carolina', 'Montana', 'Maine', 'Massachusetts',\n",
    "    'Indiana', 'Rhode_Island', 'Hawaii', 'Virginia'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9e9efd",
   "metadata": {},
   "source": [
    "## 1.2 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b87936",
   "metadata": {},
   "source": [
    "- Set up key words for health resources to filter the data\n",
    "- January 2018 to August 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57f9dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\n",
    "    \"sanitizer\",\n",
    "    \"soap\",\n",
    "    \"toilet paper\",\n",
    "    \"mask\",\n",
    "    \"disinfectant\",\n",
    "    \"gloves\",\n",
    "    \"thermometer\",\n",
    "    \"tissues\",\n",
    "    \"wipes\",\n",
    "    \"vitamins\",\n",
    "    \"face shield\",\n",
    "    \"lysol spray\",\n",
    "    \"n95\",\n",
    "    \"hand wash\",\n",
    "    \"acetaminophen\",\n",
    "    \"tylenol\",\n",
    "    \"advil\",\n",
    "    \"motrin\",\n",
    "    \"dayquil\",\n",
    "    \"nyquil\",\n",
    "    \"mucinex\",\n",
    "    \"robitussin\",\n",
    "    \"sudafed\",\n",
    "    \"test kit\",\n",
    "    \"home test\",\n",
    "    \"self test\",\n",
    "    \"ibuprofen\",\n",
    "    \"pepto-bismol\",\n",
    "    \"tums\",\n",
    "    \"robitussin\",\n",
    "    \"pedialyte\",\n",
    "    \"gatorade\",\n",
    "    \"vick’s vaporub\",\n",
    "    \"oseltamivir\",\n",
    "    \"tamiflu\",\n",
    "    \"zinc\",\n",
    "    \"hydroxychloroquine\",\n",
    "    \"respirators\",\n",
    "    \"alcohol\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8fb6495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract only the sentences containing keywords\n",
    "def extract_sentences_with_keywords(text, pattern):\n",
    "    # Split the text into sentences\n",
    "    sentences = re.split(r'[.!?]', text)\n",
    "    # Extract and return sentences containing the keywords\n",
    "    return ' | '.join([sentence.strip() for sentence in sentences if pattern.search(sentence)])\n",
    "\n",
    "# Create a regex pattern for the keywords\n",
    "pattern = re.compile('|'.join(keywords), re.IGNORECASE)\n",
    "\n",
    "# Initialize an empty DataFrame to store the filtered comments\n",
    "all_filtered_comments_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f082dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each file and process the data\n",
    "for file_name in file_list:\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # Load the data\n",
    "    reviews_df = pd.read_csv(file_path)\n",
    "\n",
    "    # Drop duplicates based on 'name' and 'text' columns\n",
    "    reviews_df.drop_duplicates(subset=['name', 'text'], inplace=True)\n",
    "    \n",
    "    # Ensure the 'time' field contains only valid timestamps\n",
    "    reviews_df = reviews_df[reviews_df['time'].apply(lambda x: isinstance(x, (int, float)))]\n",
    "    \n",
    "    # Convert timestamp to datetime\n",
    "    reviews_df['time'] = pd.to_datetime(reviews_df['time'], unit='ms')\n",
    "    \n",
    "    # Filter reviews from Jan 2018 onwards\n",
    "    filtered_reviews_df = reviews_df[reviews_df['time'] >= '2018-01-01']\n",
    "    \n",
    "    # Handle missing values in 'text' column by replacing NaNs with empty strings\n",
    "    filtered_reviews_df['text'] = filtered_reviews_df['text'].fillna('')\n",
    "    \n",
    "    # Extract only the sentences with keywords from the text\n",
    "    filtered_reviews_df['text'] = filtered_reviews_df['text'].apply(lambda x: extract_sentences_with_keywords(x, pattern))\n",
    "    \n",
    "    # Filter comments that mention any of the keywords\n",
    "    filtered_reviews_df['keywords_mentioned'] = filtered_reviews_df['text'].apply(lambda x: bool(pattern.search(x)))\n",
    "    \n",
    "    # Extract the filtered comments\n",
    "    filtered_comments_df = filtered_reviews_df[filtered_reviews_df['keywords_mentioned']]\n",
    "    \n",
    "    # Analyze the content of filtered comments\n",
    "    filtered_comments_df['mentioned_keywords'] = filtered_comments_df['text'].apply(lambda x: [kw for kw in keywords if kw in x.lower()])\n",
    "    \n",
    "    # Append the filtered comments to the main DataFrame\n",
    "    all_filtered_comments_df = pd.concat([all_filtered_comments_df, filtered_comments_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "241f4ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filtered_comments_df['class'] = np.nan\n",
    "\n",
    "all_filtered_comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cc595fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filtered_comments_df.to_csv('../filtered-labeled-data/unlabeled_review.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ab90fd",
   "metadata": {},
   "source": [
    "## 1.3 Annotation\n",
    "\n",
    "**1500 samples 80%-20% (1200 for training; 300 for testing)**\n",
    "- Class 1: They had lots of toilet paper\n",
    "- Class -1: Out of toilet paper, again…\n",
    "- Class 9: Forcing you to where a mask will be Shopping elsewhere"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
